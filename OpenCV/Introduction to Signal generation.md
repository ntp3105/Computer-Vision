# Image generation from camera

The broad diagram [Fig 1] shows the generation, recording, processing, and sensing of an image. The electromagnetic energy in the visible part of the spectrum is leaving the Sun reflected by the object, travels through the air and reaches here. A sensor a transducer which is an analog camera, that through photo-chemistry converts light energy into chemical changes on the film.

So the brighter parts of the image. We have higher concentration of silver grains and this film, after it's processed, negative or black and white film, represents analog image. The objective here is to process the image by digital computer and therefore convert the analog image to a digital one through this A/D block. In this particular case, densitometer is used to measure the concentration of the silver collide grains on the film or a scanner to end up with a digital image. Although nowadays, the digital systems are prevalent which means that these two units here are grouped together and this becomes a digital camera that we are all familiar with.

After the digital image is processed by the computer, which is the main objective of image processing, ie, using openCV, the techniques that will allow us to process digital images, seen by the human viewer. Here, the digital image is converted into an analog one and this then signal will feed into an analog monitor, which will convert the image into an electromagnetic wave that is going to reach the human visual system, aka, the eye of the observer. Again, nowadays digital monitors or flat panels are prevalent. So an LCD here will be fed by the digital signal directly.  A video adapter plays the role of the D/A converter.

The techniques used to convert analog to digital images are the sampling and quantization, performed at A/D block, and actually could be resampling or re-quantization. The main task of image processing is done in this center block where the input is a digital image and the output is another processed digital image. To demonstrate something, or better yet, resampling, let's consider this digital image. It's a 256 by 256 image, which means it has 256 rows and 256 columns and it's an eight bit image, which means that each element here which is called a pixel from picture element.   Here's 2 to the eighth.   Or one of 256 values, okay? So I'll take this image and I will down-sample it by a factor of eight in both the horizontal and the vertical directions. So out of eight samples, horizontally I'll keep one. I'll do the same in the vertical direction. Or in other words, if you consider here an eight by eight block.

I will only keep this value and throw away the rest. So I keep one and throw away 63. Okay? If I do this, then I end up with a 32 by 32 image. This tiny image shown here.   If I bring it back to the 256 by 256 dimension for visualization purposes, then that's how this image will look like. So, you see that due to this down-sampling, you see these blocking artifacts and these so-called jagged edges, right? They're not straight edges anymore, but they're jagged. Of course, to up-sample the image, I did something very simple, I used so-called zero-order hold.   Which means I just took an eight by eight block, I only had this value and we're missing the other 63 values. And I simply gave to the other 63 values the value of this, so each eight by eight block has the same value. And this is apparent by looking at this image. This is an eight by eight block, for example. And it has constant value and constant intensity.   Similarly, the idea of re-quantization is depicted here. Over here is the eight bit per pixel image we started with, so here we have two to the eighth 256 different gray values.   And right here, I have only two to the 4th equals 16 values to represent the different intensities. And over here, I go down to two to the 2nd, that is four different values. So clearly, you see the so-called contouring effects that are visible here even, right? So these are artificial contours or boundaries that have nothing to do with the original image. So you save bits clearly, we're going from eight bits to four, to two bits to represent intensity, but the same time you introduce errors, the so-called quantization errors.